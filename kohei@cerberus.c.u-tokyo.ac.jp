import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from matplotlib import pyplot as plt
import torch.optim as optim

class Model(nn.Module):
  def __init__(self):
    super(Model,self).__init__()
    vision_input_size=768
    vision_feature_size=128
    motion_input_size=2
    motion_feature_size=128
    hidden_size = 256
    self.hidden_size = hidden_size
    self.hidden_L=torch.zeros(1, 1, hidden_size).to(device) 
    self.hidden_H=torch.zeros(1, 1, hidden_size).to(device) 
    self.vision_feature_size=vision_feature_size
    self.motion_feature_size = motion_feature_size
    self.fc1_v = nn.Linear(vision_input_size, vision_feature_size)
    self.fc1_m = nn.Linear(motion_input_size, motion_feature_size)
    self.Low = nn.GRU(vision_feature_size+motion_feature_size + hidden_size, hidden_size, batch_first=True)
    self.High = nn.GRU(hidden_size, hidden_size, batch_first=True)
    self.fc2_v = nn.Linear(vision_feature_size, vision_input_size)
    self.fc2_m = nn.Linear(motion_feature_size, motion_input_size)
    

  def forward(self, v_0, m_0):
    assert m_0.shape==(1, 1000, 2)
    f_v = F.elu(self.fc1_v(v_0), alpha=1.0)
    f_m = F.elu(self.fc1_m(m_0), alpha=1.0)
    all_input = torch.cat((f_v, f_m), dim=2)
    L_input = torch.cat((all_input, self.hidden_H*torch.ones(1, 1000, self.hidden_size).to(device) ), dim=2)
    output_L , self.hidden_L= self.Low(L_input, self.hidden_L)
    output_H, self.hidden_H = self.High(self.hidden_L, self.hidden_H)
    f_v_n = F.elu(output_L[:, :, :self.vision_feature_size])
    f_m_n = F.elu(output_L[:, :, self.vision_feature_size:self.vision_feature_size+self.motion_feature_size])
    v_n = torch.sigmoid(self.fc2_v(f_v_n))
    m_n = torch.tanh(self.fc2_m(f_m_n))

    return v_n, m_n

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = Model().to(device) 

from torch.autograd import Variable
import h5py
from torch.autograd import detect_anomaly
hdfpath="data.h5"

def MSE(x, y):
    a = 0.5*torch.sum((x - y)**2)
    return a

def cross_entropy_error(y, t):
  delta = 1e-7 # マイナス無限大を発生させないように微小な値を追加
  return - (1/768)* torch.sum(t * torch.log(y + delta)+(1- t) * torch.log(1 - y + delta))

optimizer=optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))

epoch=0
with h5py.File(hdfpath,'r') as f:
  with detect_anomaly():
    model.train()
    motion_lists=f['motion/train']
    vision_lists=f['vision/train']
    loss_list=[]
    for motion_list, vision_list in zip(motion_lists, vision_lists):
      #vision_loss_list=[]
      #motion_loss_list=[]
      #100 data
      m_0=torch.from_numpy(motion_list[:1000, :])
      v_0=torch.from_numpy(vision_list[:1000, :])
      m_0, v_0 = Variable(m_0).to(device), Variable(v_0).to(device)    
      vision_output, motion_output=model(v_0.view(1, 1000, 768), m_0.view(1, 1000, 2))
      m_t=torch.from_numpy(motion_list[1:, :])
      v_t=torch.from_numpy(vision_list[1:, :])
      m_t, v_t = Variable(m_t).to(device), Variable(v_t).to(device)
      loss_vision = cross_entropy_error(vision_output, v_t)
      assert torch.isnan(loss_vision) == False
      loss_motion = MSE(motion_output, m_t)
      #vision_loss_list.append(loss_vision)
      #motion_loss_list.append(loss_motion)
      loss = loss_vision+loss_motion
      optimizer.zero_grad()
      loss.backward(retain_graph=True)
      optimizer.step()
      loss_list.append(loss)
      epoch += 1
      print("epoch{0}：終了, loss:{1} \n".format(epoch, loss))

domain= [d for d in range(len(loss_list))]
fig = plt.figure()
plt.plot(domain, loss_list)
fig.savefig('noguchi_iizuka.png')
